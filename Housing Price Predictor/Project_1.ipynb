{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1. Frame the problem\n",
    "As the contractor, I must develop an AI model that can accurately predict housing prices within in the LA area using attributes of the property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use different ML models to predict the survivability chances for a passenger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get the Data \n",
    "I will be scraping a website like RedFin in order to create my own data set of LA houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting data from page 1: https://www.zillow.com/los-angeles-ca/sold/\n",
      "Successfully fetched page 1.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 2: https://www.zillow.com/los-angeles-ca/sold/2_p/\n",
      "Successfully fetched page 2.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 3: https://www.zillow.com/los-angeles-ca/sold/3_p/\n",
      "Successfully fetched page 3.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 4: https://www.zillow.com/los-angeles-ca/sold/4_p/\n",
      "Successfully fetched page 4.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 5: https://www.zillow.com/los-angeles-ca/sold/5_p/\n",
      "Successfully fetched page 5.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 6: https://www.zillow.com/los-angeles-ca/sold/6_p/\n",
      "Successfully fetched page 6.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 7: https://www.zillow.com/los-angeles-ca/sold/7_p/\n",
      "Successfully fetched page 7.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 8: https://www.zillow.com/los-angeles-ca/sold/8_p/\n",
      "Successfully fetched page 8.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 9: https://www.zillow.com/los-angeles-ca/sold/9_p/\n",
      "Successfully fetched page 9.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 10: https://www.zillow.com/los-angeles-ca/sold/10_p/\n",
      "Successfully fetched page 10.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 11: https://www.zillow.com/los-angeles-ca/sold/11_p/\n",
      "Successfully fetched page 11.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 12: https://www.zillow.com/los-angeles-ca/sold/12_p/\n",
      "Successfully fetched page 12.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 13: https://www.zillow.com/los-angeles-ca/sold/13_p/\n",
      "Successfully fetched page 13.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 14: https://www.zillow.com/los-angeles-ca/sold/14_p/\n",
      "Successfully fetched page 14.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 15: https://www.zillow.com/los-angeles-ca/sold/15_p/\n",
      "Successfully fetched page 15.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 16: https://www.zillow.com/los-angeles-ca/sold/16_p/\n",
      "Successfully fetched page 16.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 17: https://www.zillow.com/los-angeles-ca/sold/17_p/\n",
      "Successfully fetched page 17.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 18: https://www.zillow.com/los-angeles-ca/sold/18_p/\n",
      "Successfully fetched page 18.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 19: https://www.zillow.com/los-angeles-ca/sold/19_p/\n",
      "Successfully fetched page 19.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 20: https://www.zillow.com/los-angeles-ca/sold/20_p/\n",
      "Successfully fetched page 20.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 21: https://www.zillow.com/los-angeles-ca/sold/21_p/\n",
      "Successfully fetched page 21.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 22: https://www.zillow.com/los-angeles-ca/sold/22_p/\n",
      "Successfully fetched page 22.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 23: https://www.zillow.com/los-angeles-ca/sold/23_p/\n",
      "Successfully fetched page 23.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 24: https://www.zillow.com/los-angeles-ca/sold/24_p/\n",
      "Successfully fetched page 24.\n",
      "Found 41 properties on this page.\n",
      "Requesting data from page 25: https://www.zillow.com/los-angeles-ca/sold/25_p/\n",
      "Error making request on page 25: 400 Client Error: Bad Request for url: https://www.zillow.com/los-angeles-ca/sold/25_p/\n",
      "\n",
      "Finished scraping. Found a total of 984 properties.\n",
      "\n",
      "Data successfully saved to 'zillow_sold_los_angeles.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def convert_price_to_numeric(price_str):\n",
    "    \"\"\"\n",
    "    Converts a price string (e.g., '$2.5M', '500K') to a numeric value.\n",
    "    \"\"\"\n",
    "    if price_str is None:\n",
    "        return None\n",
    "    price_str = str(price_str).strip().upper()\n",
    "    \n",
    "    if isinstance(price_str, (int, float)):\n",
    "        return price_str\n",
    "\n",
    "    price_str = price_str.replace('$', '').replace(',', '')\n",
    "    \n",
    "    if 'M' in price_str:\n",
    "        return int(float(price_str.replace('M', '')) * 1_000_000)\n",
    "    elif 'K' in price_str:\n",
    "        return int(float(price_str.replace('K', '')) * 1_000)\n",
    "    \n",
    "    try:\n",
    "        return int(price_str)\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "def scrape_zillow_sold_data(city='los-angeles', state='ca'):\n",
    "    \"\"\"\n",
    "    Scrapes sold housing data from Zillow for a given city and state,\n",
    "    handling pagination and extracting key features from search result pages.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\",\n",
    "        \"Accept-Language\": \"en\",\n",
    "        \"Cache-Control\": \"no-cache\",\n",
    "        \"Pragma\": \"no-cache\",\n",
    "        \"Sec-Ch-Ua\": '\"Chromium\";v=\"130\", \"Google Chrome\";v=\"130\", \"Not?A_Brand\";v=\"99\"',\n",
    "        \"Sec-Ch-Ua-Mobile\": \"?0\",\n",
    "        \"Sec-Ch-Ua-Platform\": '\"Windows\"',\n",
    "        \"Sec-Fetch-Dest\": \"document\",\n",
    "        \"Sec-Fetch-Mode\": \"navigate\",\n",
    "        \"Sec-Fetch-Site\": \"none\",\n",
    "        \"Sec-Fetch-User\": \"?1\",\n",
    "        \"Upgrade-Insecure-Requests\": \"1\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36\",\n",
    "    }\n",
    "    \n",
    "    all_properties = []\n",
    "    page_number = 1\n",
    "\n",
    "    while True:\n",
    "        if page_number == 1:\n",
    "            url = f\"https://www.zillow.com/{city}-{state}/sold/\"\n",
    "        else:\n",
    "            url = f\"https://www.zillow.com/{city}-{state}/sold/{page_number}_p/\"\n",
    "        \n",
    "        print(f\"Requesting data from page {page_number}: {url}\")\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            print(f\"Successfully fetched page {page_number}.\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error making request on page {page_number}: {e}\")\n",
    "            break\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        script_tag = soup.find('script', {'id': '__NEXT_DATA__'})\n",
    "        \n",
    "        if not script_tag:\n",
    "            print(\"Could not find the data script tag. The page structure may have changed.\")\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            json_data = json.loads(script_tag.string)\n",
    "            search_results = json_data['props']['pageProps']['searchPageState']['cat1']['searchResults']['listResults']\n",
    "            \n",
    "            if not search_results:\n",
    "                print(\"No more properties found. Reached the last page.\")\n",
    "                break\n",
    "            \n",
    "            page_properties = []\n",
    "            for property_data in search_results:\n",
    "                # The 'homeType' and 'parcelId' are nested deeper in the JSON. This accesses them safely.\n",
    "                hdp_data = property_data.get('hdpData', {})\n",
    "                home_info = hdp_data.get('homeInfo', {})\n",
    "                property_type = home_info.get('homeType', 'N/A')\n",
    "                # --- CHANGE START ---\n",
    "                # Get the Assessor's Identification Number (AIN), which Zillow calls parcelId\n",
    "                ain = home_info.get('parcelId')\n",
    "                # --- CHANGE END ---\n",
    "\n",
    "                page_properties.append({\n",
    "                    'Address': property_data.get('address', 'N/A'),\n",
    "                    # --- CHANGE START ---\n",
    "                    # Added the new 'AIN' field to the dictionary\n",
    "                    'AIN': ain,\n",
    "                    # --- CHANGE END ---\n",
    "                    'Sold Price': convert_price_to_numeric(property_data.get('soldPrice', property_data.get('price', 'N/A'))),\n",
    "                    'Bedrooms': property_data.get('beds'),\n",
    "                    'Bathrooms': property_data.get('baths'),\n",
    "                    'Area (SqFt)': property_data.get('area'),\n",
    "                    'Property Type': property_type,\n",
    "                })\n",
    "            \n",
    "            all_properties.extend(page_properties)\n",
    "            print(f\"Found {len(page_properties)} properties on this page.\")\n",
    "            \n",
    "            page_number += 1\n",
    "            time.sleep(2) # Increased delay to be more respectful to the server\n",
    "\n",
    "        except (KeyError, json.JSONDecodeError) as e:\n",
    "            print(f\"Error parsing JSON data: {e}. The data structure might have changed.\")\n",
    "            break\n",
    "\n",
    "    if not all_properties:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(f\"\\nFinished scraping. Found a total of {len(all_properties)} properties.\")\n",
    "    return pd.DataFrame(all_properties)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scraped_data = scrape_zillow_sold_data(city='los-angeles', state='ca')\n",
    "\n",
    "    if not scraped_data.empty:\n",
    "        output_filename = 'zillow_sold_los_angeles.csv'\n",
    "        scraped_data.to_csv(output_filename, index=False)\n",
    "        print(f\"\\nData successfully saved to '{output_filename}'\")\n",
    "    else:\n",
    "        print(\"\\nScraping failed or no data was found. No file was saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore the Data\n",
    "Gain insights into the data you have from step 2, making sure to identify any bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that sex has the largest tell for survivability, females being 75% and amle only being ~20%\n",
    "Passenger class and age are close seconds with about ~63% for first class (gets lower as class decreases) and 60% for ages 10 and under.\n",
    "The apparent bias is that Women, children, and wealthy passengers were prioritized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Prepare the Data\n",
    "\n",
    "\n",
    "Apply any data transformations and explain what and why\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filled in missing values for age, embarked, and fare using median, mode, and median respectively. This was because the model can only work with numbers.\n",
    "Converted sex to numbers (male =0, f =1)\n",
    "\n",
    "When i was doing research on the problem, i found that family size had a great effect, so I learned how to make a derived variable for familiy size and \n",
    "if thjey were alone or not.\n",
    "\n",
    "Also created a Title variable to get iunformation that may be missing in the table such as if the person is married, or their estimated age.\n",
    "\n",
    "Removed uselesss features like Cabin (too many missing), Name(useless....), and Ticket(formatting was different among the values so i couldnt use it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model the data\n",
    "Using selected ML models, experment with your choices and describe your findings. Finish by selecting a Model to continue with\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Didnt even try linear regression as there are too many features. \n",
    "\n",
    "Tried logistic regression in vscode. Got a 80% accuracy, but after doing more research i found that people had sucess with random forests, \n",
    "so I stuck with that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Fine Tune the Model\n",
    "\n",
    "With the select model descibe the steps taken to acheve the best rusults possiable \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when I began i started with only 50 tress, but i realized that was too few and it was overfitting the model, so I bumped it up to 400 trees and things were fine.\n",
    "I asked chatgpt about it and it explained that with the amount of rows in the data, 200 trees was sufficient, so i stuck with that.\n",
    "\n",
    "I read that with less than 5k rows, the max depth should be 5-10, so i just chose 7 and stuck with it.\n",
    "\n",
    "I just started at 1 for the random state and started playing with it and hit 45 as the highest percentage of 82 and stuck with it, but really it doesnt\n",
    "matter, its just something used to ensure the data is reproducible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Present\n",
    "In a customer faceing Document provide summery of finding and detail approach taken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of Findings and Approach\n",
    "We analyzed passenger survivability on the titanic using a dataset provided from Kaggle. Our analysis aimed to identify which factors most influenced survival and to develop a predictive model. From the data:\n",
    "Sex is the strongest predictor: Females had a roughly 75% survival rate, while males were around 20%.\n",
    "\n",
    "\n",
    "Passenger class and age are also significant: First-class passengers had a survival rate of ~63%, decreasing with lower classes, and children aged 10 and under had about a 60% chance of survival.\n",
    "\n",
    "\n",
    "Bias in survival: The data reflects historical prioritization of women, children, and wealthier passengers.\n",
    "\n",
    "\n",
    "Cleaning the data:\n",
    "Missing values were filled in\n",
    "Categorical variables were converted\n",
    "New features were created, like family size and title.\n",
    "Useless features were removed\n",
    "\n",
    "\n",
    "For modeling:\n",
    "Initial testing with logistic regression had 80% accuracy.\n",
    "Moved to Random Forest model\n",
    "Model optimization:\n",
    "\n",
    "\n",
    "Number of trees: Increased from 50 (overfitting) to 200.\n",
    "\n",
    "\n",
    "Max depth: Set to 7, as it is a small dataset\n",
    "Set a random state to make sure the results are reproduced\n",
    "Outcome: The Random Forest model gave an accuracy of approximately 82%. Therefore, it can be reliably used to predict whether a passenger will survive or not, given a new set of data..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Launch the Model System\n",
    "Define your production run code, This should be self susficent and require only your model pramaters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(params):\n",
    "    params = params.reindex(columns=X.columns, fill_value=0)\n",
    "    results = model.predict(params)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
